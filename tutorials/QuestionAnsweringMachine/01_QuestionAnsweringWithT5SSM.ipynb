{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6cb03f7",
   "metadata": {},
   "source": [
    "# FAQ Bot - Q&A model, trained using pairs of questions and answers\n",
    "\n",
    "Fine tune a large language model with a list of question and answers. This approach os called Closed Book Q&A because the model doesn't require context and is capable of answering variations of the questions you provide in your dataset.\n",
    "\n",
    "This is an evolution of classic ChatBots because LLMs like T5 can disambiguate and generalize better than the old technologies we find in these ChatBots services.\n",
    "\n",
    "For that purpose you'll use a **[T5 SMALL SSM ~80MParams](https://huggingface.co/google/t5-small-ssm)** model, accelerated by a trn1 instance ([AWS Trainium](https://aws.amazon.com/machine-learning/trainium/)), running on [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "\n",
    "The dataset is the content of all **AWS FAQ** pages, downloaded from: https://aws.amazon.com/faqs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb78690",
   "metadata": {},
   "source": [
    "## 1) Install some dependencies and check permissions\n",
    "You need a more recent version of **SageMaker** Python Library. After this install you'll need to restart the kernel.\n",
    "\n",
    "In addition you'll be using [SageMaker Studio Image Build](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/) to deploy your image. If you have not previously used it please follow that link and setup the required IAM permissions for your SageMaker role.\n",
    "\n",
    ">**If you have not setup IAM permissions to the ECR repositiory in `image_uri`, do so now to prevent errors.**\n",
    "\n",
    ">**If you have never before done a SageMaker training job with Trn1, you'll need to do a service level request. This can take a few hours, best to make the request early so you don't have to wait.**\n",
    "\n",
    "You can edit this URL to go directly to the page to request the increase:\n",
    "\n",
    "`https://<region>.console.aws.amazon.com/servicequotas/home/services/sagemaker/quotas/L-79A1FE57`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ae05a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install sagemaker-studio-image-build\n",
    "%pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a951ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "if not sagemaker.__version__ >= \"2.146.0\": print(\"You need to upgrade or restart the kernel if you already upgraded\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Make changes here to use an existing repository and/or tag\n",
    "repo_name=\"sagemaker-studio-pytorch-training-neuron\"\n",
    "image_tag=\"1.13.1-neuron-py38-sdk2.9.0-ubuntu20.04\"\n",
    "\n",
    "image_name=f\"{repo_name}:{image_tag}\"\n",
    "image_uri=f\"{sess.account_id()}.dkr.ecr.{sess.boto_region_name}.amazonaws.com/{repo_name}:{image_tag}\"\n",
    "print(image_name)\n",
    "print(image_uri)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {bucket}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60dba6",
   "metadata": {},
   "source": [
    "## 2) Visualize and upload the dataset\n",
    "Take note of the S3 URI here if you get interrupted, no need to reupload later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855c1822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ec2/autoscaling/faqs/</td>\n",
       "      <td>What is Amazon EC2 Auto Scaling?</td>\n",
       "      <td>Amazon EC2 Auto Scaling is a fully managed ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ec2/autoscaling/faqs/</td>\n",
       "      <td>When should I use Amazon EC2 Auto Scaling vs. ...</td>\n",
       "      <td>You should use AWS Auto Scaling to manage scal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ec2/autoscaling/faqs/</td>\n",
       "      <td>How is Predictive Scaling Policy different fro...</td>\n",
       "      <td>Predictive Scaling Policy brings the similar p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ec2/autoscaling/faqs/</td>\n",
       "      <td>What are the benefits of using Amazon EC2 Auto...</td>\n",
       "      <td>Amazon EC2 Auto Scaling helps to maintain your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ec2/autoscaling/faqs/</td>\n",
       "      <td>What is fleet management and how is it differe...</td>\n",
       "      <td>If your application runs on Amazon EC2 instanc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  service                                           question  \\\n",
       "0  /ec2/autoscaling/faqs/                   What is Amazon EC2 Auto Scaling?   \n",
       "1  /ec2/autoscaling/faqs/  When should I use Amazon EC2 Auto Scaling vs. ...   \n",
       "2  /ec2/autoscaling/faqs/  How is Predictive Scaling Policy different fro...   \n",
       "3  /ec2/autoscaling/faqs/  What are the benefits of using Amazon EC2 Auto...   \n",
       "4  /ec2/autoscaling/faqs/  What is fleet management and how is it differe...   \n",
       "\n",
       "                                             answers  \n",
       "0  Amazon EC2 Auto Scaling is a fully managed ser...  \n",
       "1  You should use AWS Auto Scaling to manage scal...  \n",
       "2  Predictive Scaling Policy brings the similar p...  \n",
       "3  Amazon EC2 Auto Scaling helps to maintain your...  \n",
       "4  If your application runs on Amazon EC2 instanc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv.gz', compression='gzip', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e1b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_uri = sess.upload_data(path='train.csv.gz', key_prefix='datasets/aws-faq/train')\n",
    "print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44643986",
   "metadata": {},
   "source": [
    "## 3) Build a custom container image with NeuronSDK 2.9+\n",
    "NeuronSDK 2.9+ is required to deal with T5. We'll take a pre-existing container with NeuronSDK 2.8 and upgrade it. To build the docker image and upload it to ECR, we'll make use of **sagemaker-studio-image-build**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa193542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('container'): os.mkdir('container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac63cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting container/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile container/Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training-neuron:1.13.0-neuron-py38-sdk2.8.0-ubuntu20.04\n",
    "\n",
    "RUN apt update && apt install -y \\\n",
    "    aws-neuronx-dkms=2.* \\\n",
    "    aws-neuronx-tools=2.* \\\n",
    "    aws-neuronx-collectives=2.* \\\n",
    "    aws-neuronx-runtime-lib=2.* \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip3 install -U pip\n",
    "RUN pip3 install --force-reinstall neuronx-cc==2.* torch-neuronx torchvision==0.14.1 transformers==4.27.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af7f09-cb0e-4075-9106-fc97ccc0e866",
   "metadata": {},
   "source": [
    "### Use sm-docker to build our image\n",
    "Due to instance memeory issues, BUILD_GENERAL1_MEDIUM seems to be best.\n",
    "We'll use `image_name` for our repo (will create properly as long as permissions were setup according to the [documentation here](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de023dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sm-docker build container --compute-type BUILD_GENERAL1_MEDIUM --repository $image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd77a3",
   "metadata": {},
   "source": [
    "## 4) Prepare the train/inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b28590cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir('src'): os.mkdir('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27761ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize src/question_answering.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e8b7c0",
   "metadata": {},
   "source": [
    "## 5) Kick-off our fine tuning job on Amazon SageMaker\n",
    "We need to create a SageMaker Estimator first and then invoke **.fit**. \n",
    "\n",
    "Please, notice we're passing the parameter **checkpoint_s3_uri**. This is important because NeuronSDK will spend some time compiling the model before fine tuning it. The compiler saves the model to cache files and, with this param, the files will be uploaded to **S3**. So, next time we run a job, NeuronSDK can just load back the cache files and start training immediately.\n",
    "\n",
    "When training for the first time, the training job takes ~9 hours to process all 60 Epochs on an **inf1.32xlarge**.\n",
    "\n",
    "\n",
    "If you need to wait for a quota increase like I did. When you come back, run cell 2 to setup the sagemaker session and S3 uris, etc. Then run the below to get the process started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ece0fa-34c1-4f1b-bc4d-bc6fc4a662c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# manually set S3 bucket:\n",
    "# s3_uri = \"s3://sagemaker-us-west-2-430432044279/datasets/aws-faq/train/train.csv.gz\"\n",
    "# s3_uri = \"s3://sagemaker-<region>-<accountID>/datasets/aws-faq/train/train.csv.gz\"\n",
    "print(s3_uri)\n",
    "\n",
    "# manually set to the image uri given by sm-docker\n",
    "# image_uri = \"430432044279.dkr.ecr.us-west-2.amazonaws.com/sagemaker-studio-d-io5zhcigtblg:neuron-labs-1677869849323\"\n",
    "# image_uri = \"<accountID>.dkr.ecr.<region>.amazonaws.com/<repo>:<tag>\"\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7f8c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/aws/deep-learning-containers/blob/master/available_images.md#neuron-containers\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"question_answering.py\", # Specify your train script\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.trn1.32xlarge',\n",
    "    image_uri=image_uri,\n",
    "    disable_profiler=True,\n",
    "    output_path=f\"s3://{bucket}/output\",\n",
    "    \n",
    "    # Parameters required to enable checkpointing\n",
    "    # This is necessary for caching XLA HLO files and reduce training time next time    \n",
    "    checkpoint_s3_uri=f\"s3://{bucket}/checkpoints\",\n",
    "    volume_size = 512,\n",
    "    distribution={\n",
    "        \"torch_distributed\": {\n",
    "            \"enabled\": True\n",
    "        }\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"model-name\": \"t5-small-ssm\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"num-epochs\": 60\n",
    "    },\n",
    "    metric_definitions=[\n",
    "        {'Name': 'train:loss', 'Regex': 'loss:(\\S+);'}\n",
    "    ]\n",
    ")\n",
    "estimator.framework_version = '1.13.1' # workround when using image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4e4ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit({\"train\": s3_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f082b4",
   "metadata": {},
   "source": [
    "## 6) Deploy our model to a SageMaker endpoint\n",
    "Here, we're using a pre-defined HuggingFace model class+container to just load our fine tuned model on a CPU based instance: c6i.4xlarge (an Intel Xeon based machine).\n",
    "\n",
    ">If you're picking this up later uncomment line 4, fill in the path to your model artifacts, comment line 9 out, and uncomment line 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99525273-1626-4a97-be8a-8211542d21bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90af272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and modify this if you're picking this back up later and your training was sucessful.\n",
    "# you'll need to get the model s3 URI from sagemaker -> Training -> Training Jobs -> <Your job name> -> Output -> S3 model artifact\n",
    "\n",
    "# pre_trained_model = YOUR_S3_PATH\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=estimator.model_data,       # path to your model and script\n",
    "   # model_data=pre_trained_model,       # path to your model and script\n",
    "   role=role,                             # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26.0\",         # transformers version used\n",
    "   pytorch_version=\"1.13.1\",              # pytorch version used\n",
    "   py_version='py39',                     # python version used\n",
    "   sagemaker_session=sess,\n",
    "   \n",
    "   # for production it is important to define vpc_config and use a vpc_endpoint\n",
    "   #vpc_config={\n",
    "   #    'Subnets': ['subnet-A-REPLACE', 'subnet-B-REPLACE'],\n",
    "   #    'SecurityGroupIds': ['sg-A-REPLACE', 'sg-B-REPLACE']\n",
    "   #}    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c6i.4xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f12446",
   "metadata": {},
   "source": [
    "## 7) Run a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e393b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is S3?\n",
      "A: S3 is an Amazon of the S3 storage that provides a generic way to store and process data between a single file. You can use S3 in the cloud to process data in the cloud without worryinging your application or managing. You can use S3 in AWS services as well as custom-built\n",
      "\n",
      "Q: What is EC2?\n",
      "A: Amazon EC2 is a new type of computing Machine that can be deployed to web, deploy, and scale web web of your application. With EC2, you can run your applications without having to use the internet to manage your application or business intelligence.\n",
      "\n",
      "Q: What are the benefits of using Application Load Balencer?\n",
      "A: Application Load Balencer enabless applications the load and complexity of applications across multiple applications, allowing you to easily configure applications (e.g., network network, network network, etc.) using Network Load Balens.\n",
      "\n",
      "Q: What is SageMaker JumpStart?\n",
      "A: SageMaker JumpStart is a new ML capability tool that helps you quickly launch, deploy, and deploy your data and applications. You can quickly launch AWS devices and use the feature-built-in feature from your data source to quickly deploy the features and deploy deploy from your data source notebook to instantly\n",
      "\n",
      "CPU times: user 11.9 ms, sys: 578 µs, total: 12.5 ms\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "questions = [\n",
    "    \"What is SageMaker?\",\n",
    "    \"What is EC2 AutoScaling?\",\n",
    "    \"What are the benefits of autoscaling?\"\n",
    "]\n",
    "resp = predictor.predict({'inputs': questions})\n",
    "# print(resp)\n",
    "for q,a in zip(questions, resp['answer']):\n",
    "    print(f\"Q: {q}\\nA: {a}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cd7c8a",
   "metadata": {},
   "source": [
    "## 8) Clean up\n",
    "This will delete the model and the endpoint you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5595be-cc64-40b9-b33b-9b503bdefa28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
